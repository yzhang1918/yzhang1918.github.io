<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ylog</title>
    <link>https://yzhang1918.github.io/</link>
    <description>Recent content on Ylog</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>©2020 yzhang1918</copyright>
    <lastBuildDate>Thu, 25 Nov 2021 23:37:41 +0800</lastBuildDate><atom:link href="https://yzhang1918.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>[置顶] Paper速查 - Graph</title>
      <link>https://yzhang1918.github.io/posts/paper_comments_graph/</link>
      <pubDate>Thu, 25 Nov 2021 23:37:41 +0800</pubDate>
      
      <guid>https://yzhang1918.github.io/posts/paper_comments_graph/</guid>
      <description>Graph的文章读太多了，专门开一页吧。 Node Embedding Dynamic Graphs Graph Neural Networks Architecture Pooling Sampling Heterogeneous Networks Theory Misc. Explainability Node Embedding [GraphWave] Donnat et al., Learning Structural Node Embeddings via Diffusion Wavelets. KDD&#39;2018. 将graph heat kernel（即wavele</description>
    </item>
    
    <item>
      <title>[置顶] Paper速查</title>
      <link>https://yzhang1918.github.io/posts/paper_comments/</link>
      <pubDate>Tue, 07 Apr 2020 15:03:44 +0800</pubDate>
      
      <guid>https://yzhang1918.github.io/posts/paper_comments/</guid>
      <description>开个新坑，把读过的paper用一行评论总结，只说优点不说缺点。 Recommender Systems Collaborative Filtering Graph Based Point Process External Memory Attention Time Embedding NLP Summarization Code Rule-based Models Confidence Calibration Misc Recommender Systems Collaborative Filtering [EASER] Steck. Embarrassingly Shallow Autoencoders for Sparse Data. WWW&#39;2019. 定义了一个</description>
    </item>
    
    <item>
      <title>[GCO系列-番外01] ClusterNet</title>
      <link>https://yzhang1918.github.io/posts/clusternet/</link>
      <pubDate>Wed, 08 Apr 2020 11:36:05 +0800</pubDate>
      
      <guid>https://yzhang1918.github.io/posts/clusternet/</guid>
      <description>Motivation Related Work ClusterNet Forward Pass Backward Pass A Visual Proof Solving the Optimization Problems Experimental Results Conclusion Wilder et al., End to End Learning and Optimization on Graphs. NeurIPS&#39;2019. 这篇是我在遍历Graph Combinatorial Optimization相关工作过程中发现的一篇pap</description>
    </item>
    
    <item>
      <title>[GCO系列-前篇01] structure2vec</title>
      <link>https://yzhang1918.github.io/posts/s2v/</link>
      <pubDate>Thu, 26 Mar 2020 21:24:03 +0800</pubDate>
      
      <guid>https://yzhang1918.github.io/posts/s2v/</guid>
      <description>Pairwise Markov Random Field Hilbert Space Embedding of Distributions Embedding Mean-Field Inference Conclusion structure2vec是一个我很喜欢的图神经网络模型，发表于ICML&#39;16。虽然文章引用也不少，但远没有Kip</description>
    </item>
    
    <item>
      <title>图卷积GCN的直观理解</title>
      <link>https://yzhang1918.github.io/posts/gcn_intuition/</link>
      <pubDate>Mon, 17 Feb 2020 20:51:33 +0800</pubDate>
      
      <guid>https://yzhang1918.github.io/posts/gcn_intuition/</guid>
      <description>实验室又有新生进来了，也有对图卷积感兴趣的，那就写篇文章，简单的讲一下。本篇文章参考了Kipf的博客，主要是直观的理解，加上我的一点解读，数</description>
    </item>
    
    <item>
      <title>GAE</title>
      <link>https://yzhang1918.github.io/posts/gae/</link>
      <pubDate>Thu, 02 Jan 2020 22:29:38 +0800</pubDate>
      
      <guid>https://yzhang1918.github.io/posts/gae/</guid>
      <description>GAE Proof To prove $\mathbb{E}\left[ \sum_{t=0}^\infty \Psi_t \nabla \log\pi(a_t|s_t) \right] = \nabla \mathbb{E}[\sum_{t=0}^\infty r_t]$, we only need to prove $\mathbb{E}[\Psi_t\nabla\log\pi(a_t|s_t)] = \mathbb{E}[(\sum_{t&#39;=0}^\infty r_{t&#39;})\nabla\log\pi(a_t|s_t)],~\forall t$.
Reward-to-go  $$ \begin{aligned} &amp; \mathbb{E}_{s_{0:\infty}, a_{0:\infty}} \left[ \left( \sum_{t&#39;=t}^\infty r_{t&#39;} \right) \nabla \log \pi(a_t|s_t) \right] \\ =&amp; \mathbb{E}_{s_{0:\infty}, a_{0:\infty}} \left[ \left( \sum_{t&#39;=0}^{\infty} r_{t&#39;} \right) \nabla \log \pi(a_t|s_t) \right] - \mathbb{E}_{s_{0:\infty}, a_{0:\infty}} \left[ \left( \sum_{t&#39;=0}^{t-1} r_{t&#39;} \right) \nabla \log \pi(a_t|s_t) \right] \\ =&amp; \mathbb{E}_{s_{0:\infty}, a_{0:\infty}} \left[ \left( \sum_{t&#39;=0}^{\infty} r_{t&#39;} \right) \nabla \log \pi(a_t|s_t) \right] - \mathbb{E}_{s_{0:t}, a_{0:t}} \left[ \left( \sum_{t&#39;=0}^{t-1} r_{t&#39;} \right) \nabla \log \pi(a_t|s_t) \right] \\ =&amp; \mathbb{E}_{s_{0:\infty}, a_{0:\infty}} \left[ \left( \sum_{t&#39;=0}^{\infty} r_{t&#39;} \right) \nabla \log \pi(a_t|s_t) \right] - \mathbb{E}_{s_{0:t-1}, a_{0:t-1}} \left[ \left( \sum_{t&#39;=0}^{t-1} r_{t&#39;} \right) \mathbb{E}_{s_t, a_t}[\nabla \log \pi(a_t|s_t) |s_{t-1}, a_{t-1}] \right] \\ =&amp; \mathbb{E}_{s_{0:\infty}, a_{0:\infty}} \left[ \left( \sum_{t&#39;=0}^{\infty} r_{t&#39;} \right) \nabla \log \pi(a_t|s_t) \right] - \mathbb{E}_{s_{0:t-1}, a_{0:t-1}} \left[ \left( \sum_{t&#39;=0}^{t-1} r_{t&#39;} \right) \cdot 0 \right] \\ =&amp; \mathbb{E}_{s_{0:\infty}, a_{0:\infty}} \left[ \left( \sum_{t&#39;=0}^{\infty} r_{t&#39;} \right) \nabla \log \pi(a_t|s_t) \right].</description>
    </item>
    
    <item>
      <title>Soft Policy Iteration</title>
      <link>https://yzhang1918.github.io/posts/sac/</link>
      <pubDate>Thu, 02 Jan 2020 20:17:15 +0800</pubDate>
      
      <guid>https://yzhang1918.github.io/posts/sac/</guid>
      <description>This is a note on the soft policy iteration from SAC12.
 Soft Policy Evaluation Soft Policy Improvement Soft Policy Iteration Other References    Soft Policy Evaluation We define the bellman backup operator for any $Q: \mathcal{S\times A} \rightarrow \Re$:
 $$ \mathcal{T}^\pi Q(s_t, a_t) \triangleq r(s_t, a_t) + \gamma \mathbb{E}_{s_{t+1} \sim p} [V(s_{t+1})] $$ where we have the soft state value function:
$$V(s_t) = \mathbb{E}_{a_t\sim \pi}[Q(s_t, a_t) - \alpha \log\pi(a_t|s_t)] $$</description>
    </item>
    
    <item>
      <title>About</title>
      <link>https://yzhang1918.github.io/about/</link>
      <pubDate>Wed, 01 Jan 2020 22:29:38 +0800</pubDate>
      
      <guid>https://yzhang1918.github.io/about/</guid>
      <description>Currently, I am a postdoctoral researcher at Fudan University. Before that, I received my Ph.D. degree at Fudan University in 2021 under the supervision of Prof. Yangyong Zhu and Prof. Yun Xiong. In addition, I was a visiting student at WPI working with Prof. Xiangnan Kong and a research intern at MSRA (Shanghai) working with Dr. Dongsheng Li. My research interests center around graph data mining and deep learning. My</description>
    </item>
    
    <item>
      <title>2020</title>
      <link>https://yzhang1918.github.io/posts/2020/</link>
      <pubDate>Wed, 01 Jan 2020 20:53:09 +0800</pubDate>
      
      <guid>https://yzhang1918.github.io/posts/2020/</guid>
      <description>我又双叒叕换博客了。 之前用了MWeb和语雀，一开始觉得还行，但用了一段时间各种问题都出现了。 MWeb不够灵活，本质还是个Markdown编辑</description>
    </item>
    
  </channel>
</rss>
