<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8" />
	<meta http-equiv="X-UA-Compatible" content="IE=edge"><title>[置顶] Paper速查 - Ylog</title><link rel="icon" type="image/png" href=icons/Y.png /><meta name="viewport" content="width=device-width, initial-scale=1">
	<meta property="og:title" content="[置顶] Paper速查" />
<meta property="og:description" content="用一行评论总结paper" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://yzhang1918.github.io/posts/paper_comments/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-04-07T15:03:44&#43;08:00" />
<meta property="article:modified_time" content="2020-04-07T15:03:44&#43;08:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="[置顶] Paper速查"/>
<meta name="twitter:description" content="用一行评论总结paper"/>
<link href="https://fonts.googleapis.com/css?family=Ubuntu:300,400,300italic,400italic|Raleway:200,300" rel="stylesheet">

	<link rel="stylesheet" type="text/css" media="screen" href="https://yzhang1918.github.io/css/normalize.css" />
	<link rel="stylesheet" type="text/css" media="screen" href="https://yzhang1918.github.io/css/main.css" />

	<script src="https://cdn.jsdelivr.net/npm/feather-icons/dist/feather.min.js"></script>
	<script src="https://yzhang1918.github.io/js/main.js"></script>
</head>


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/&#43;DiW/UqRcLbRjq" crossorigin="anonymous"><script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l&#43;B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd&#43;qj&#43;o24G5ZU2zJz" crossorigin="anonymous"></script><script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
            onload="renderMathInElement(document.body, {
                delimiters: [
                    {left: '$$', right: '$$', display: true},
                    {left: '\\[', right: '\\]', display: true},
                    {left: '$', right: '$', display: false},
                    {left: '\\(', right: '\\)', display: false}
                ]
            });"></script>
        

<body>
	<div class="container wrapper post">
		<div class="header">
	<h1 class="site-title"><a href="https://yzhang1918.github.io/">Ylog</a></h1>
	<div class="site-description"><h2>yzhang1918&rsquo;s Blog</h2><nav class="nav social">
			<ul class="flat"><a href="https://github.com/yzhang1918" title="Github"><i data-feather="github"></i></a><a href="https://www.instagram.com/yaozh1918/" title="Instagram"><i data-feather="instagram"></i></a><a href="/index.xml" title="RSS"><i data-feather="rss"></i></a></ul>
		</nav>
	</div>

	<nav class="nav">
		<ul class="flat">
			
			<li>
				<a href="/posts">All posts</a>
			</li>
			
			<li>
				<a href="/categories">Categories</a>
			</li>
			
			<li>
				<a href="/tags">Tags</a>
			</li>
			
			<li>
				<a href="/about">About</a>
			</li>
			
		</ul>
	</nav>
</div>


		<div class="post-header">
			<h1 class="title">[置顶] Paper速查</h1>
			<div class="meta">Posted at &mdash; Apr 7, 2020</div>
		</div>

		<div class="post-tags">
			
				
				<nav class="nav">
						<ul class="flat">
							
							<li class="tags"><a href="/tags/reference">reference</a></li>
							
							
							<li class="categories"><a href="/categories/paper-reading">paper-reading</a></li>
							
							<li class="categories"><a href="/categories/research">research</a></li>
							
						</ul>
				</nav>
				
			
		</div>

		<div class="markdown">
			<p>开个新坑，把读过的paper用一行评论总结，只说优点不说缺点。</p>
<div class="toc">
<nav id="TableOfContents">
  <ul>
    <li><a href="#recommender-systems">Recommender Systems</a>
      <ul>
        <li><a href="#collaborative-filtering">Collaborative Filtering</a></li>
        <li><a href="#graph-based">Graph Based</a></li>
      </ul>
    </li>
    <li><a href="#point-process">Point Process</a></li>
    <li><a href="#external-memory">External Memory</a></li>
    <li><a href="#attention">Attention</a>
      <ul>
        <li><a href="#time-embedding">Time Embedding</a></li>
      </ul>
    </li>
    <li><a href="#nlp">NLP</a>
      <ul>
        <li><a href="#summarization">Summarization</a></li>
        <li><a href="#code">Code</a></li>
      </ul>
    </li>
    <li><a href="#rule-based-models">Rule-based Models</a></li>
    <li><a href="#confidence-calibration">Confidence Calibration</a></li>
    <li><a href="#misc">Misc</a></li>
  </ul>
</nav>
</div>
<h2 id="recommender-systems">Recommender Systems</h2>
<h3 id="collaborative-filtering">Collaborative Filtering</h3>
<p><code>[EASER] Steck. Embarrassingly Shallow Autoencoders for Sparse Data. WWW'2019.</code></p>
<blockquote>
<p>定义了一个简单的约束优化问题，类似auto-encoder，要求利用其他交互信息还原对单点的预测；求解出closed-form solution发现了其对应了preicision matrix，进而关联到了MRF。</p>
</blockquote>
<p><code>Steck. Markov Random Fields for Collaborative Filtering. NeurIPS'2019.</code></p>
<blockquote>
<p>与WWW'2019相反，先定义了MRF，给出了优化目标（pseudo-likelihood），发现是www'2019中的优化问题；同样要求解precision matrix；给出了一个稀疏化后的近似版本。</p>
</blockquote>
<h3 id="graph-based">Graph Based</h3>
<p><code>[NGCF] Wang et al., Neural Graph Collaborative Filtering. SIGIR'2019.</code></p>
<blockquote>
<p>将GCN用到CF上；message的构造利用了user与item的element-wise product；对比了message dropout与node dropout的效果。</p>
</blockquote>
<p><code>[LightGCN] He et al., LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation. SIGIR'2020.</code></p>
<blockquote>
<p>实验验证了NGCF中的feature transformation与nonlinearity对推荐无帮助；提出了LightGCN，只利用了第一层的embedding与aggregation；讨论了与SGC、APPNP的关系。</p>
</blockquote>
<p><code>[RMGCNN] Monti et al., Geometric Matrix Completion with Recurrent Multi-Graph Neural Networks. NeurIPS'2017.</code></p>
<blockquote>
<p>引入了column/row graphs，即user间的网络与item间的网络，提出了在两个dimension的分别做卷积的MGCNN；利用RNN建模score的传播过程，增量更新矩阵；大多数数据集上手工构建了k-NN graphs。</p>
</blockquote>
<p><code>[GCMC] Berg et al., Graph Convolutional Matrix Completion. KDD'2018.</code></p>
<blockquote>
<p>user-item二分图上用auto-encoder建模；用交叉熵优化explicit feedback；不同的rating有着不同的权重进行message passing，类似multi-channel；ordinal weight sharing能部分地捕捉到ratings之间的序；node dropout直接抛弃某节点的全部传出信号；onehot+节点属性。</p>
</blockquote>
<p><code>[GHP] Shang and Sun. Geometric Hawkes Processes with Graph Convolutional Recurrent Neural Networks. AAAI'2019.</code></p>
<blockquote>
<p>RMGCNN的输出用Hawkes Process来建模。</p>
</blockquote>
<h2 id="point-process">Point Process</h2>
<p><code>[N-SM-MPP] Mei and Eisner, The Neural Hawkes Process: A Neurally Self-Modulating Multivariate Point Process. NeurIPS'2017.</code></p>
<blockquote>
<p>提出了一个continuous LSTM用于建模intensity；泛化了HP的self-excitation性质，还可以捕捉self-inhibition与inertia，即self-modulating；实验做了对缺失数据的讨论。</p>
</blockquote>
<p><code>[GMHP] Liu et al., Exploiting Graph Regularized Multi-dimensional Hawkes Processes for Modeling Events with Spatio-temporal Characteristics. IJCAI'2018.</code></p>
<blockquote>
<p>将图结构prior加入到MHP中；采用multi-view的方式，将MHP的influence matrix与图的connection matrix在子空间上对齐。</p>
</blockquote>
<h2 id="external-memory">External Memory</h2>
<p><code>[DNC] Alex et al., Hybrid computing using a neural network with dynamic external memory. Nature. 2016.</code></p>
<blockquote>
<p>类似NTM，但细节提升了非常多，包括memory usage indicator表示memory的空闲位置，temporal links表示数据的写入顺序；实验进行了图上的一些强化学习任务。</p>
</blockquote>
<h2 id="attention">Attention</h2>
<p><code>[GA-Net] Xue et al., Not All Attention Is Needed: Gated Attention Network for Sequence Data. AAAI'2020.</code></p>
<blockquote>
<p>提出了gated attention用于RNN上；引入auxiliary network输出0-1的值，从中sample binary gate，决定哪些位置不需要attend；利用gumbel softmax训练。</p>
</blockquote>
<p><code>Luong et al., Effective Approaches to Attention-based Neural Machine Translation. EMNLP'2015.</code></p>
<blockquote>
<p>提出了global attention和local attention；local attention机制先输出一个中心位置，然后用一个window将左右两边的词包裹在内，计算attention。</p>
</blockquote>
<h3 id="time-embedding">Time Embedding</h3>
<p><code>[FLOATER] Liu et al., Learning to Encode Position for Transformer  with Continuous Dynamical Model. ICML'2020.</code></p>
<blockquote>
<p>将Transformer中的Position encoding用NeuralODE代替，可以退化为Position encoding。</p>
</blockquote>
<h2 id="nlp">NLP</h2>
<h3 id="summarization">Summarization</h3>
<p><code>[MathchSum] Zhong et al., Extractive Summarization as Text Matching. ACL'2020.</code></p>
<blockquote>
<p>提出了基于semantic matching的summary-level的extractive summarization模型；两阶段，第一阶段利用BertSum剪枝原始文本，并生成候选集，第二阶段则用Siamese-BERT对candidates进行匹配。</p>
</blockquote>
<h3 id="code">Code</h3>
<p><code>[GraphCodeBERT] Guo et al., GraphCodeBERT: Pre-training Code Representations with Data Flow. arXiv'2020.</code></p>
<blockquote>
<p>将Data Flow Graph引入BERT，提出了graph-guided masked attention，实际上可以看作是GAT。提出了3个pre-training tasks：传统的MLM；Data Flow上的edge prediction；Data Flow的节点和代码中的token对齐。在4个下游任务做了验证：code search, clone detection, code translation, and code reﬁnement.</p>
</blockquote>
<h2 id="rule-based-models">Rule-based Models</h2>
<p><code>[CRS] Wang et al., Transparent Classification with Multilayer Logical Perceptrons and Random Binarization. AAAI'2020.</code></p>
<blockquote>
<p>CNF和DNF层交替；连续版本引入Random Binarization。</p>
</blockquote>
<p><code>[RRL] Wang et al., Scalable Rule-Based Representation Learning for Interpretable Classification. NeurIPS'2021.</code></p>
<blockquote>
<p>CRS的升级版本；binarization layer不可训练，随机选端点；logical layer同时学CNF和DNF；最后加一层线性层；应对离散问题，提出了Gradient Grafting，将离散版本模型与连续版本模型的梯度进行嫁接。</p>
</blockquote>
<h2 id="confidence-calibration">Confidence Calibration</h2>
<p><code>[EOW-Softmax] Wang et al., Energy-Based Open-World Uncertainty Modeling for Confidence Calibration. ICCV'2021.</code></p>
<blockquote>
<p>对于K类分类任务，引入K+1类用于建模uncertainty，利用EBM模型定义loss，利用SGLD优化；证明了K+1类与marginal distribution成负相关。</p>
</blockquote>
<h2 id="misc">Misc</h2>
<p><code>[ClusterNet] Wilder et al., End to End Learning and Optimization on Graphs. NeurIPS'2019.</code></p>
<blockquote>
<p>关注decision-focused learning，将optimization solver嵌入到神经网络中；提出了可微的k-means层，做节点聚类。</p>
</blockquote>
<p><code>Chen et al., Neural Ordinary Differential Equations. NeurIPS'2018.</code></p>
<blockquote>
<p>将residual连接看作微分方程的Euler离散化，进而得到ODE；利用adjoint计算梯度，可以计算关于所有输入的梯度，而不需要知道solver的实现；对连续版本的Normalizing Flow计算有着一定的简化。</p>
</blockquote>
<p><code>Müller et al., When Does Label Smoothing Help? NeurIPS'2019.</code></p>
<blockquote>
<p>分析了Label Smoothing的作用，从倒数第二层（penultimate）的表征来看，LS会使得同一个class下的样本点的表征形成更tight的簇，同时保证距离其他class的簇有相同的距离(equidistant)，这保证了generalization和calibration（效果同Temperature Scaling）；但作为teacher，由于equidistant会丢失class之间的相关性信息，导致student不能很好学习。</p>
</blockquote>

		</div>
<script src="https://utteranc.es/client.js"
    repo="yzhang1918/blog_comments"
    issue-term="pathname"
    label="Comment"
    theme="github-light"
    crossorigin="anonymous"
    async>
</script></div>
	<div class="footer wrapper">
	<nav class="nav">
		<div> ©2020 yzhang1918 |  <a href="https://github.com/yzhang1918/ezhil">Theme</a>  Modified from <a href="https://github.com/vividvilla/ezhil">Ezhil</a> | Built with <a href="https://gohugo.io">Hugo</a></div>
	</nav>
</div>



<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-77357711-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

<script>feather.replace()</script>
</body>
</html>
