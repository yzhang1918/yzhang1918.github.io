<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Ylog</title>
    <link>https://yzhang1918.github.io/posts/</link>
    <description>Recent content in Posts on Ylog</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>©2020 yzhang1918</copyright>
    <lastBuildDate>Wed, 08 Apr 2020 11:36:05 +0800</lastBuildDate><atom:link href="https://yzhang1918.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>[置顶] Paper速查</title>
      <link>https://yzhang1918.github.io/posts/paper_comments/</link>
      <pubDate>Tue, 07 Apr 2020 15:03:44 +0800</pubDate>
      
      <guid>https://yzhang1918.github.io/posts/paper_comments/</guid>
      <description>开个新坑，把读过的paper用一行评论总结，只说优点不说缺点。 Graph Node Embedding Temporal Network Embedding Graph Neural Networks Explainability Recommender Systems Collaborative Filtering Graph Based Point Process External Memory Attention NLP Summarization Code Rule-based Models Misc Graph Node Embedding [GraphWave] Donnat et al., Learning Structural Node Embeddings via</description>
    </item>
    
    <item>
      <title>[GCO系列-番外01] ClusterNet</title>
      <link>https://yzhang1918.github.io/posts/clusternet/</link>
      <pubDate>Wed, 08 Apr 2020 11:36:05 +0800</pubDate>
      
      <guid>https://yzhang1918.github.io/posts/clusternet/</guid>
      <description>Motivation Related Work ClusterNet Forward Pass Backward Pass A Visual Proof Solving the Optimization Problems Experimental Results Conclusion Wilder et al., End to End Learning and Optimization on Graphs. NeurIPS&#39;2019. 这篇是我在遍历Graph Combinatorial Optimization相关工作过程中发现的一篇pap</description>
    </item>
    
    <item>
      <title>[GCO系列-前篇01] structure2vec</title>
      <link>https://yzhang1918.github.io/posts/s2v/</link>
      <pubDate>Thu, 26 Mar 2020 21:24:03 +0800</pubDate>
      
      <guid>https://yzhang1918.github.io/posts/s2v/</guid>
      <description>Pairwise Markov Random Field Hilbert Space Embedding of Distributions Embedding Mean-Field Inference Conclusion structure2vec是一个我很喜欢的图神经网络模型，发表于ICML&#39;16。虽然文章引用也不少，但远没有Kip</description>
    </item>
    
    <item>
      <title>图卷积GCN的直观理解</title>
      <link>https://yzhang1918.github.io/posts/gcn_intuition/</link>
      <pubDate>Mon, 17 Feb 2020 20:51:33 +0800</pubDate>
      
      <guid>https://yzhang1918.github.io/posts/gcn_intuition/</guid>
      <description>实验室又有新生进来了，也有对图卷积感兴趣的，那就写篇文章，简单的讲一下。本篇文章参考了Kipf的博客，主要是直观的理解，加上我的一点解读，数</description>
    </item>
    
    <item>
      <title>Soft Policy Iteration</title>
      <link>https://yzhang1918.github.io/posts/sac/</link>
      <pubDate>Thu, 02 Jan 2020 20:17:15 +0800</pubDate>
      
      <guid>https://yzhang1918.github.io/posts/sac/</guid>
      <description>This is a note on the soft policy iteration from SAC12.
 Soft Policy Evaluation Soft Policy Improvement Soft Policy Iteration Other References    Soft Policy Evaluation We define the bellman backup operator for any $Q: \mathcal{S\times A} \rightarrow \Re$:
 $$ \mathcal{T}^\pi Q(s_t, a_t) \triangleq r(s_t, a_t) + \gamma \mathbb{E}_{s_{t+1} \sim p} [V(s_{t+1})] $$ where we have the soft state value function:
$$V(s_t) = \mathbb{E}_{a_t\sim \pi}[Q(s_t, a_t) - \alpha \log\pi(a_t|s_t)] $$</description>
    </item>
    
    <item>
      <title>2020</title>
      <link>https://yzhang1918.github.io/posts/2020/</link>
      <pubDate>Wed, 01 Jan 2020 20:53:09 +0800</pubDate>
      
      <guid>https://yzhang1918.github.io/posts/2020/</guid>
      <description>我又双叒叕换博客了。 之前用了MWeb和语雀，一开始觉得还行，但用了一段时间各种问题都出现了。 MWeb不够灵活，本质还是个Markdown编辑</description>
    </item>
    
  </channel>
</rss>
